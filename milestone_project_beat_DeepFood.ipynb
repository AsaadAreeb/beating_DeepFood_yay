{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MedOebUy4xVW",
    "outputId": "578b2276-e445-45d9-ddfc-a1785897b8b1"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eomL2Iy87yhE"
   },
   "source": [
    "## Get helper functions\n",
    "\n",
    "In the past modules we created some helper functions to do small tasks.\n",
    "\n",
    "Rather than rewrite all of these, we can import a script and load them in from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKcS5fqb-yP6"
   },
   "outputs": [],
   "source": [
    "# Import series of helper functions for our notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10-imxfEEbqg"
   },
   "outputs": [],
   "source": [
    "# Get TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2RxeTHvIbEX",
    "outputId": "f216a330-fabd-4875-cd4a-8be6e2bf4af1"
   },
   "outputs": [],
   "source": [
    "# List all the available datasets\n",
    "datasets_list = tfds.list_builders() # get all available datasets in TFDS\n",
    "print(\"food101\" in datasets_list) # is our target dataset in the list of TFDS datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcRbG2IrUCkf"
   },
   "outputs": [],
   "source": [
    "# Load in the data (takes 5-6 minutes in Google Colab)\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
    "                                             split=[\"train\", \"validation\"],\n",
    "                                             shuffle_files=True,\n",
    "                                             as_supervised=True, # data gets returned in tuple format (data, label)\n",
    "                                             with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fW6XVrPxbyx3"
   },
   "source": [
    "## Exploring the Food101 data from TensorFlow Datasets\n",
    "\n",
    "To beecome one with our data, we want to find:\n",
    "* Class names\n",
    "* The shape of our input data (image tensors)\n",
    "* The datatype of our input data\n",
    "* What the labels look like (e.g. are they one-hot encoded or are they label encoded)\n",
    "* Do the labels match up with the class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMKu3iTxXvWy",
    "outputId": "74ac6cff-395e-417b-aed4-578522f66611"
   },
   "outputs": [],
   "source": [
    "# Features of Food101 from TFDS\n",
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyscFVSdbLGZ",
    "outputId": "aebb1b22-3e88-4e95-9cbd-ad4274b6e678"
   },
   "outputs": [],
   "source": [
    "# Get the class names\n",
    "class_names = ds_info.features[\"label\"].names\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVFt3CNZeOSP"
   },
   "outputs": [],
   "source": [
    "# Take one sample of our train data\n",
    "train_one_sample = train_data.take(1) # samples are in format (image_tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uka3Li7yeze3",
    "outputId": "8e58be21-f6d8-4fee-d6ad-ef7bd4cccc19"
   },
   "outputs": [],
   "source": [
    "# What does one sample of our training data look like?\n",
    "train_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KU2_f4e0fEU3",
    "outputId": "6ffcf88f-c613-4ed6-9baa-0388aabfb710"
   },
   "outputs": [],
   "source": [
    "# Output info about our training sample\n",
    "for image, label in train_one_sample:\n",
    "  print(f\"\"\"\n",
    "  image shape: {image.shape}\n",
    "  image datatype: {image.dtype}\n",
    "  Target class from Food101 (tensor form): {label}\n",
    "  Class name (str form): {class_names[label.numpy()]}\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWnqBkYfgkC1",
    "outputId": "a2a1c5a0-07cb-415e-fb43-750a8574945b"
   },
   "outputs": [],
   "source": [
    "# What does our image tensor from TFDS's Food101 look like?\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16lBl7Lah-j9",
    "outputId": "b30d5f1c-b0d9-4914-9c57-18891a934deb"
   },
   "outputs": [],
   "source": [
    "# What are the min and max values of our image tensor?\n",
    "import tensorflow as tf\n",
    "tf.reduce_min(image), tf.reduce_max(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA6v-f8piff8"
   },
   "source": [
    "### Plot an image from TensorFLow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "7gi6c-v1iy2i",
    "outputId": "293ef3d1-bf24-4f25-985b-d69a15bc6d23"
   },
   "outputs": [],
   "source": [
    "# Plot an image tensor\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.title(class_names[label.numpy()]) # Add title to image to verify the label is associated with the right image\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kQ8yGxRj9dQ"
   },
   "source": [
    "## Create preprocessing functions for our data\n",
    "\n",
    "Neural networks perform best when data is in a certain way (e.g. bathed, normalized, etc).\n",
    "\n",
    "However, not all data (including data from TensorFlow Datasets) comes like this.\n",
    "\n",
    "So in order to get it ready for neural network, you'll have to often write preprocessing functions and map it to your data.\n",
    "\n",
    "What we know about our data:\n",
    "* In `uint8` datatype\n",
    "* Comprised of all different size tensors (different sized images)\n",
    "* Not scaled (pixel values are between 0 & 255)\n",
    "\n",
    "What we know models like:\n",
    "* Data in `float32` dtype (or for mixed precision `float16` and `float32`)\n",
    "* For batches, TensorFlow likes all of the tensors within a batch to be of the same size\n",
    "* Scaled (values between 0 & 1) also called normalized tensors generally perform better\n",
    "\n",
    "With these points in mind, we've got a few things we can tackle with a preprocessing function.\n",
    "\n",
    "Since we're going to be using an EfficientNetBX pretrained model from tf.keras.applications we don't need to rescale our data (these architectures have rescaling built-in).\n",
    "\n",
    "This means our function needs to:\n",
    "1. Reshape our images to all the same size\n",
    "2. Convert the dtype of our image tensors from `uint8` to `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7QlNLIbmcRW"
   },
   "outputs": [],
   "source": [
    "# Make a function for preprocessing images\n",
    "def preprocess_img(image, label, img_shape=224):\n",
    "  \"\"\"\n",
    "  Converts image datatype from `uint8` -> `float32` and reshapes\n",
    "  image to [img_shape, img_shape, colour_channels].\n",
    "  \"\"\"\n",
    "  image = tf.image.resize(image, [img_shape, img_shape]) # reshape target image\n",
    "# image = image/255. # scale image values (not required with EfficientNetBX models from tf.keras.applications) \n",
    "  return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlgK7bD5twbO",
    "outputId": "607658d7-84dc-4579-ef36-bb05aa0e6e64"
   },
   "outputs": [],
   "source": [
    "# Preprocess a single sample image and check the outputs\n",
    "preprocessed_image = preprocess_img(image, label)[0]\n",
    "print(f\"Image before preprocessing:\\n {image[:2]}..., \\nShape: {image.shape}, \\nDatatype: {image.dtype}\\n\")\n",
    "print(f\"Image after preprocessing:\\n {preprocessed_image[:2]}..., \\nShape: {preprocessed_image.shape}, \\nDatatype: {preprocessed_image.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFLP4hnnwNz8"
   },
   "source": [
    "## Batch and prepare datasets\n",
    "\n",
    "We're now going to make our data input pipeline run really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaDO9Nge0Ndf"
   },
   "outputs": [],
   "source": [
    "# Map preprocessing function to training (and parallelize it)\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Map preprocessing funcction to test data\n",
    "test_data = test_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Higo44kuC1sE"
   },
   "source": [
    "## Create modeling callbacks\n",
    "\n",
    "We're going to create a couple of callbacks to help us while our model trains:\n",
    "* TensorBoard callback to log training results (so we can visualize them later if need be)\n",
    "* ModelCheckpoint callback to save our model's progress after feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJMBPciSJkfW"
   },
   "outputs": [],
   "source": [
    "# Create tensorboard callback (import from helper_functions.py)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a ModelCheckpoint callback to save our model's progress during training\n",
    "checkpoint_path = \"model_checkpoints/cp.ckpt\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      monitor= \"val_accuracy\",\n",
    "                                                      save_best_only=True,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      verbose=0) # don't print whether or not model is being saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tM0Tu312KU-Y"
   },
   "source": [
    "## Setup mixed precission training\n",
    "\n",
    "Mixed precision utilizes a combination of float32 and float16 datatypes to speed up model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfpQ1iCgOfCu",
    "outputId": "baf33807-809c-4eef-b5c2-f532d3a5446b"
   },
   "outputs": [],
   "source": [
    "# Turn on mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\") # set global data policy to mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5RNO1y1P7uu",
    "outputId": "e8590f02-c9e0-48fd-f98e-4b81adab6894"
   },
   "outputs": [],
   "source": [
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19RWMEcBRTTH"
   },
   "source": [
    "## Build our feature extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lc6gpS7cKMz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Create base model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create functional model\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "# Note: EfficientNetBX models have rescaling built-in but if your model doesn't you can have a layer like below\n",
    "# x = preprocessing.Rescaling(1./255)(x)\n",
    "x = base_model(inputs, training=False) # Make sure layers which shoud be in inference (not training) mode stay like that\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(len(class_names))(x)\n",
    "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6s5bdstVo_px",
    "outputId": "64ae9862-71cb-4f64-e48f-b868c730d2aa"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCDDf5UHqn0d"
   },
   "source": [
    "## Checking layer dtype policies (are we using mixed precision?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56vO7XCcpc7n",
    "outputId": "45a2cd3b-56c0-4f9e-db0d-eb2cfd794e9c"
   },
   "outputs": [],
   "source": [
    "# Check the dtype_policy attributes of layers in our model\n",
    "for layer in model.layers:\n",
    "  print(f\"Name: {layer.name}, Trainable: {layer.trainable}, Stored in: {layer.dtype}, Datatype policy: {layer.dtype_policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq05KnAMpb8s"
   },
   "source": [
    "Going through the above we see:\n",
    "* `layer.name`: the human readable name of a particular layer\n",
    "* `layer.trainable`: is the layer trainable or not? (if `False`, the weights are frozen)\n",
    "* `layer.dtype`: the data type a layer stores it's variables in\n",
    "* `layer.dtype_policy`: the data type policy a layer computes on it's vaiables with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmFTMI4Z0AS0",
    "outputId": "ddcd6eba-8ba5-4c98-b65c-4293c2abb0a5"
   },
   "outputs": [],
   "source": [
    "# Check the dtype_policies attributes of layers in the base_model\n",
    "for layer in model.layers[1].layers[:20]: # check the layers of the base_model (layer at the index 1 of `model`)\n",
    "  print(f\"Name: {layer.name}, Trainable: {layer.trainable}, Stored in: {layer.dtype}, Datatype policy: {layer.dtype_policy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6PzFkgs0BF-",
    "outputId": "d43ba0c9-9b0f-4a71-883d-b8e2dd622c67"
   },
   "outputs": [],
   "source": [
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "la_D6E2S6Zr0"
   },
   "source": [
    "## Fit the feature extraction model\n",
    "\n",
    "If our goal is to fine-tune a pretrained model, the general order of doing things is:\n",
    "1. Build a feature extraction model (train a couple of output layers with base layers frozen)\n",
    "2. Fine-tune some of the frozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyYNxLZKp-S9",
    "outputId": "6129080d-785f-4973-e851-2668d049bb28"
   },
   "outputs": [],
   "source": [
    "# Fit the feature extraction model with callbacks\n",
    "history_101_food_classes_feature_extract = model.fit(train_data,\n",
    "                                                     epochs=3,\n",
    "                                                     steps_per_epoch=(len(train_data)),\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=int(0.15 * len(test_data)),\n",
    "                                                     callbacks=[create_tensorboard_callback(dir_name=\"training_logs\",\n",
    "                                                                                            experiment_name=\"efficientnetb0_101_classes_all_data_feature_extract\"),\n",
    "                                                                model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us-9EflswfGQ",
    "outputId": "b4320465-bcdf-4359-db2b-9e6b8f23fce2"
   },
   "outputs": [],
   "source": [
    "# Evaluate model on whole test dataset\n",
    "results_feature_extract_model = model.evaluate(test_data)\n",
    "results_feature_extract_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfK1nCP-51mb"
   },
   "source": [
    "### Saving & loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RANCCO-r52kT",
    "outputId": "4d096feb-2450-4172-8e86-62f7c326b5fe"
   },
   "outputs": [],
   "source": [
    "# Save our fine-tuned model\n",
    "model.save(\"drive/MyDrive/07_models/feature_extraction_mixed_precision_efficientnetb0_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMSvbAky53El",
    "outputId": "f1e1d7b5-d8ae-4ea7-c72a-1dd6eee7d990"
   },
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"drive/MyDrive/07_models/feature_extraction_mixed_precision_efficientnetb0_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSMCJGIy534s",
    "outputId": "9974c871-2fe5-4813-9294-b4ec7505a426"
   },
   "outputs": [],
   "source": [
    "# Check the layers in the base model and see what dtype policy they're using\n",
    "for layer in loaded_model.layers[1].layers[:20]:\n",
    "  print(f\"Name: {layer.name}, Trainable: {layer.trainable}, Stored in: {layer.dtype}, Datatype policy: {layer.dtype_policy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ocs3n52a54HI",
    "outputId": "53d2036f-3b0a-43ed-e1d8-9b02014abd29"
   },
   "outputs": [],
   "source": [
    "results_loaded_model = loaded_model.evaluate(test_data)\n",
    "results_loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0fyLtO254Wc",
    "outputId": "d7325fc3-855a-4105-fdb2-20b5de7e1e33"
   },
   "outputs": [],
   "source": [
    "# The loaded model's results should equal (or at least be very close) to the model's results prior to saving\n",
    "# Note: this will only work if you've instatiated results variables\n",
    "import numpy as np\n",
    "np.isclose(results_feature_extract_model, results_loaded_model).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayA9ZSpim3Fe",
    "outputId": "758e8744-8fff-43bc-f4ac-f8009df815aa"
   },
   "outputs": [],
   "source": [
    "# Download the saved model from Google Storage\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI5kxyvinPBQ",
    "outputId": "b207ac25-8c47-42f5-a64b-50f93dfd9814"
   },
   "outputs": [],
   "source": [
    "# Unzip the SavedModel downloaded from Google Stroage\n",
    "!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n",
    "!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBf6w336nVLi",
    "outputId": "a4cf85fd-6713-46d2-ecfb-bd01d38408f6"
   },
   "outputs": [],
   "source": [
    "# Load and evaluate downloaded GS model\n",
    "loaded_gs_model = tf.keras.models.load_model(\"/content/downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_m8eDIFtKVC",
    "outputId": "99939a25-49b1-4376-ae4a-9a1853dcabd3"
   },
   "outputs": [],
   "source": [
    "loaded_gs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iiph-cPtNoi",
    "outputId": "5173e684-cf07-4a6b-f154-cfb46c132589"
   },
   "outputs": [],
   "source": [
    "results_loaded_gs_model = loaded_gs_model.evaluate(test_data)\n",
    "results_loaded_gs_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh56I5TC6CV_"
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkcLCmC-tUrC",
    "outputId": "77d930c4-e909-4766-8085-2c354c0db600"
   },
   "outputs": [],
   "source": [
    "# Set all the layers in loaded_model (there are two loaded models [loaded_model, loaded_gs_model] you can choose) to trainable\n",
    "for layer in loaded_model.layers:\n",
    "  layer.trainable = True\n",
    "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "In3pxgjwtU_N",
    "outputId": "dd901a73-3050-4bce-9c75-70af9ef45067"
   },
   "outputs": [],
   "source": [
    "# Check the layers in the base model and see what dtype policy they're using\n",
    "for layer in loaded_model.layers[1].layers[:20]:\n",
    "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ4ZRjyK6HqH"
   },
   "source": [
    "### Some more callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVSkAhOZtVM8"
   },
   "outputs": [],
   "source": [
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                  patience=3)\n",
    "\n",
    "# Create ModelCheckpoint callback to save best model during fine-tuning\n",
    "checkpoint_path = \"fine_tune_checkpoints/\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      save_best_model=True,\n",
    "                                                      monitor=\"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iWht8wEtVaY"
   },
   "outputs": [],
   "source": [
    "# Create Learning Rate Reduction callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1,\n",
    "                                                 min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1O4vswd6L3l"
   },
   "source": [
    "## Compiling & Fitting the Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdGF3QxVtVnF"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "loaded_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nR-uuf9mtV0S",
    "outputId": "5d7cc61f-15fb-4d4c-e8bd-dfd9b9220df6"
   },
   "outputs": [],
   "source": [
    "# Start to fine-tune (all layers)\n",
    "history_101_food_classes_fine_tune = loaded_model.fit(train_data,\n",
    "                                                      epochs=100,\n",
    "                                                      steps_per_epoch=len(train_data),\n",
    "                                                      validation_data=test_data,\n",
    "                                                      validation_steps=int(0.15 * len(test_data)),\n",
    "                                                      callbacks=[create_tensorboard_callback(dir_name=\"training_logs\",\n",
    "                                                                                             experiment_name=\"efficientb0_101_all_data_fine_tuning\"), # track the model training logs\n",
    "                                                                 model_checkpoint, # save only the best model during training\n",
    "                                                                 early_stopping, # stop model after X epochs of no improvements\n",
    "                                                                 reduce_lr]) # reduce the learning rate after X epochs of no improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnmP1PGv6ZYH"
   },
   "source": [
    "### Saving the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9i0VIzxx3Pto",
    "outputId": "91182b25-aeb1-4342-acca-c85aa2df9e79"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "loaded_model.save(\"/content/drive/MyDrive/07_models/07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sdjCRHi41td",
    "outputId": "7f9cc480-7497-4440-a7a4-acf8d3c4c1ad"
   },
   "outputs": [],
   "source": [
    "# Evaluate mixed precision trained loaded model\n",
    "results_loaded_model_fine_tuned = loaded_model.evaluate(test_data)\n",
    "results_loaded_model_fine_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUqhtOHX7UrW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
